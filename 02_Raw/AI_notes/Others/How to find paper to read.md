# 
LÃ€M SAO Äá»‚ Äá»ŒC NHIá»€U BÃ€I BÃO NGHIÃŠN Cá»¨U HÆ N?
ğŸ“Œ LÃ m sao Ä‘á»ƒ tÃ¬m cÃ¡c paper phÃ¹ há»£p?
TrÆ°á»›c khi Ä‘á»c má»™t bÃ i bÃ¡o nghiÃªn cá»©u, báº¡n pháº£i dÃ nh thá»i gian Ä‘á»ƒ tÃ¬m má»™t bÃ i phÃ¹ há»£p. VÃ¬ váº­y, mÃ¬nh sáº½ chia sáº» má»™t sá»‘ cÃ´ng cá»¥ mÃ¬nh thÆ°á»ng sá»­ dá»¥ng khi tÃ¬m kiáº¿m paper.
TrÆ°á»›c háº¿t, báº¡n cáº§n cÃ³ má»™t chá»§ Ä‘á». Giáº£ sá»­ báº¡n muá»‘n nghiÃªn cá»©u cÃ¡ch transformers Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o computer vision. Sau Ä‘Ã³, khi xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c chá»§ Ä‘á» nÃ y, mÃ¬nh sáº½ sá»­ dá»¥ng 42 Papers (https://42papers.com/search?q=vision%20transformer) hoáº·c Arxiv Sanity (http://www.arxiv-sanity.com/search?q=vision+transformer) vÃ  nháº­p â€œvision transformersâ€â€ Ä‘á»ƒ tÃ¬m kiáº¿m cÃ¡c paper cÃ¹ng chá»§ Ä‘á». Cáº£ hai trang web nÃ y Ä‘á»u lÃ  má»™t thÆ° viá»‡n tuyá»‡t vá»i bao gá»“m cÃ¡c bÃ i bÃ¡o thuá»™c â€œhÃ ng tuyá»ƒnâ€ cá»§a Arxiv. CÃ²n giáº£ sá»­ báº¡n cÃ³ má»™t task cá»¥ thá»ƒ trong Ä‘áº§u, cháº³ng háº¡n nhÆ° "image matting", Ä‘á» cáº­p Ä‘áº¿n viá»‡c loáº¡i bá» ná»n cá»§a má»™t bá»©c áº£nh vÃ  chá»‰ Ä‘á»ƒ láº¡i Ä‘á»‘i tÆ°á»£ng quan tÃ¢m lÃ m tiá»n cáº£nh. Trong trÆ°á»ng há»£p Ä‘Ã³, báº¡n cÃ³ thá»ƒ trá»±c tiáº¿p sá»­ dá»¥ng Papers With Code nhÆ° mÃ¬nh Ä‘Ã£ lÃ m á»Ÿ Ä‘Ã¢y (https://paperswithcode.com/task/image-matting), trang nÃ y cÅ©ng khÃ¡ há»¯u Ã­ch, cung cáº¥p cÃ¡c paper tá»‘t nháº¥t hiá»‡n táº¡i cho task mÃ  báº¡n muá»‘n giáº£i quyáº¿t báº±ng cÃ¡ch cung cáº¥p cÃ¡c Ä‘oáº¡n code Ä‘á»ƒ triá»ƒn khai tÃ¡c vá»¥ mÃ  báº¡n cáº§n.
Náº¿u báº¡n khÃ´ng cÃ³ chá»§ Ä‘á» nÃ o trong Ä‘áº§u, báº¡n cÅ©ng cÃ³ thá»ƒ chá»n má»™t bÃ i bÃ¡o theo xu hÆ°á»›ng báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ nÃ y: 
- 42 Papers (Link: https://42papers.com/search?q=vision%20transformer)
- Daily Papers (Link: https://papers.labml.ai/papers/daily): Hiá»ƒn thá»‹ táº¥t cáº£ cÃ¡c bÃ i bÃ¡o thá»‹nh hÃ nh trÃªn Twitter.
Giá» báº¡n Ä‘Ã£ cÃ³ má»™t vÃ i tÃ i liá»‡u trong danh sÃ¡ch chá» Ä‘á»c, tuy nhiÃªn vui lÃ²ng khÃ´ng Ä‘á»c táº¥t cáº£ tá»«ng bÃ i má»™t. Thay vÃ o Ä‘Ã³, hÃ£y thá»­ cÃ¡ch tiáº¿p cáº­n mÃ  mÃ¬nh suggest sau, nÃ³ cÃ³ thá»ƒ giÃºp báº¡n tiáº¿t kiá»‡m ráº¥t nhiá»u thá»i gian Ä‘áº¥y:
Äáº§u tiÃªn, mÃ¬nh sáº½ kiá»ƒm tra toÃ n bá»™ cÃ¡c tÃ i liá»‡u má»™t lÆ°á»£t vÃ  xÃ¡c nháº­n ráº±ng bÃ i bÃ¡o Ä‘Ã³ cÃ³ Ä‘Ã¡ng Ä‘á»c hay khÃ´ng. Náº¿u bÃ i bÃ¡o Ä‘Ã³ tham kháº£o má»™t vÃ i nguá»“n khÃ´ng phÃ¹ há»£p, Ä‘Ã³ háº³n khÃ´ng pháº£i lÃ  má»™t dáº¥u hiá»‡u tá»‘t. TÆ°Æ¡ng tá»± nhÆ° váº­y, má»™t máº¹o nhanh Ä‘á»ƒ giÃºp tÃ¬m ra má»™t bÃ i bÃ¡o cÃ³ Ä‘Ã¡ng Ä‘á»c hay khÃ´ng lÃ  trá»±c quan hoÃ¡ cÃ¡c nguá»“n Ä‘Æ°á»£c trÃ­ch dáº«n trong bÃ i Ä‘Ã³. Äá»ƒ lÃ m Ä‘Æ°á»£c viá»‡c nÃ y, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ´ng cá»¥ cÃ³ tÃªn lÃ  Connected Papers (https://www.connectedpapers.com/) Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ káº¿t ná»‘i giá»¯a táº¥t cáº£ cÃ¡c nguá»“n tham kháº£o trong paper cá»§a báº¡n, chá»‰ cáº§n báº¡n nháº­p vÃ o tÃªn cá»§a paper Ä‘Ã³. Sao viá»‡c check source láº¡i quan trá»ng? Náº¿u cÃ¡c source Ä‘Æ°á»£c káº¿t ná»‘i vá»›i nhau vÃ  Ä‘Æ°á»£c nhiá»u ngÆ°á»i biáº¿t Ä‘áº¿n, paper nÃ y Ä‘Ã¡ng tin Ä‘áº¥y! Táº¥t nhiÃªn, Ä‘Ã¢y chá»‰ lÃ  má»™t dáº¥u hiá»‡u nháº­n biáº¿t chá»§ quan xem liá»‡u má»™t bÃ i bÃ¡o cÃ³ nÃªn Ä‘á»c hay khÃ´ng thÃ´i nhÃ©! DÃ¹ sao thÃ¬ báº¡n cÅ©ng khÃ´ng nÃªn Ä‘Ã¡nh giÃ¡ hoÃ n toÃ n má»™t bÃ i bÃ¡o chá»‰ dá»±a trÃªn sá»‘ lÆ°á»£ng trÃ­ch dáº«n cá»§a nÃ³.
Má»™t khi cÃ¡c paper Ä‘Ã£ vÆ°á»£t qua Ä‘Æ°á»£c bÃ i kiá»ƒm tra Ä‘áº§u tiÃªn vá»›i cÃ¡c nguá»“n tham kháº£o Ä‘Ã¡ng tin cáº­y, hÃ£y Ä‘á»c nhanh cÃ¡c má»¥c sau: tiÃªu Ä‘á», abstract, keyword vÃ  conclusion. HÃ£y xem liá»‡u chÃºng cÃ³ thá»±c sá»± nÃ³i vá» nhá»¯ng gÃ¬ báº¡n Ä‘ang tÃ¬m kiáº¿m hay khÃ´ng. Báº±ng cÃ¡ch nÃ y, báº¡n sáº½ nhanh chÃ³ng náº¯m Ä‘Æ°á»£c cÃ¡c Ã½ cÆ¡ báº£n vá» paper Ä‘Ã³ vÃ  giÃºp báº¡n quyáº¿t Ä‘á»‹nh xem báº¡n cÃ³ muá»‘n tiáº¿p tá»¥c Ä‘á»c nÃ³ hay khÃ´ng.
á» vÃ²ng chá»n lá»c thá»© 2, hÃ£y Ä‘i sÃ¢u hÆ¡n má»™t chÃºt vÃ o cÃ¡c paper. NhÃ¬n vÃ o cÃ¡c biá»ƒu Ä‘á»“ vÃ  báº£ng, Ä‘á»c chÃº thÃ­ch cá»§a chÃºng. Báº¡n cÅ©ng cÃ³ thá»ƒ xem nhanh pháº§n introduction vÃ  related works Ä‘á»ƒ xem liá»‡u báº¡n cÃ³ tháº¥y nÃ³ thÃº vá»‹ vÃ  Ä‘Æ°á»£c thá»±c hiá»‡n tá»‘t hay khÃ´ng, nhÆ°ng Ä‘á»«ng Ä‘i sÃ¢u vÃ o method vÃ  experiment ngay láº­p tá»©c nhÃ©, báº¡n sáº½ máº¥t nhiá»u thá»i gian Ä‘á»ƒ tiÃªu hÃ³a kiáº¿n thá»©c vÃ  hiá»ƒu chÃºng Ä‘áº¥y. Láº§n chá»n lá»c thá»© hai nÃ y sáº½ giÃºp báº¡n náº¯m Ä‘Æ°á»£c Ä‘á»™ sÃ¢u vÃ  sáº¯c cá»§a bÃ i bÃ¡o!
Danh sÃ¡ch chá» Ä‘á»c cá»§a chÃºng ta cÃ³ váº» Ä‘Ã£ Ä‘Æ°á»£c thu háº¹p láº¡i Ä‘Ã¡ng ká»ƒ. Giá» báº¡n chá»‰ cáº§n Ä‘á»c cÃ¡c bÃ i bÃ¡o thÃ´i. Tuy nhiÃªn, Ä‘á»«ng chá»‰ Ä‘á»c nÃ³. HÃ£y Ä‘i sÃ¢u vÃ o nÃ³. Láº¥y bÃºt chÃ¬, bÃºt Ä‘Ã¡nh dáº¥u ra vÃ  tÃ¬m má»™t khÃ´ng gian yÃªn tÄ©nh Ä‘á»ƒ báº¯t Ä‘áº§u Ä‘á»c thÃ´i. CÃ¡ nhÃ¢n mÃ¬nh thÃ¬ thÆ°á»ng thÃ­ch in cÃ¡c paper ra vÃ  Ä‘á»c trÃªn giáº¥y, nhÆ°ng khÃ¡ lÃ  tá»‘n kÃ©m vÃ¬ cÃ³ nhá»¯ng paper ráº¥t dÃ i hoáº·c cÅ©ng khÃ´ng tiá»‡n cÃ³ mÃ¡y in Ä‘á»ƒ in ngay nÃªn mÃ¬nh Ä‘ang Ä‘ang chuyá»ƒn sang Ä‘á»c trÃªn mÃ¡y tÃ­nh báº±ng PDF Adobe Acrobat Reader, vá»› pháº§n má»m nÃ y báº¡n cÃ³ thá»ƒ Ä‘Ã¡nh dáº¥u, váº½ vÃ  thÃªm note trÃªn PDF. 
BÃªn cáº¡nh Ä‘Ã³, báº¡n cÅ©ng nÃªn Google cÃ¡c tá»« vÃ  khÃ¡i niá»‡m mÃ  báº¡n khÃ´ng hiá»ƒu vÃ  xem láº¡i cÃ¡c trÃ­ch dáº«n khi tÃ¡c giáº£ Ä‘á» cáº­p Ä‘áº¿n. Bá» qua nhá»¯ng Ä‘iá»u nÃ y sáº½ lÃ m áº£nh hÆ°á»Ÿng Ä‘áº¿n sá»± hiá»ƒu biáº¿t cá»§a báº¡n vá» toÃ n bá»™ bÃ i bÃ¡o. CÃ²n náº¿u báº¡n lÃ  ngÆ°á»i má»›i báº¯t Ä‘áº§u Ä‘á»c paper, hÃ£y lÆ°u Ã½ nhá»¯ng chá»— báº¡n khÃ´ng hiá»ƒu Ä‘Ã¡nh dáº¥u báº¥t ká»³ chá»— nÃ o báº¡n tháº¥y cÃ³ váº» phá»©c táº¡p hoáº·c khÃ´ng rÃµ rÃ ng. Báº¡n cÃ³ thá»ƒ google cÃ¡c cÃ¢u há»i ngay láº­p tá»©c, nhÆ°ng Ä‘á»«ng Ä‘á»ƒ bá»‹ máº¯c káº¹t náº¿u chÃºng váº«n cÃ²n sau láº§n Ä‘á»c thá»© 2! Bjan cÃ³ thá»ƒ nhá» báº¡n bÃ¨ hoáº·c náº¿u báº¡n khÃ´ng biáº¿t há»i ai thÃ¬ cÃ³ thá»ƒ tÃ¬m Ä‘áº¿n cÃ¡c cá»™ng Ä‘á»“ng hoáº·c diá»…n Ä‘Ã n! CÃ³ ráº¥t nhiá»u cá»™ng Ä‘á»“ng tuyá»‡t vá»i, nÆ¡i báº¡n cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i 24/7 vÃ  nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i, vÃ­ dá»¥ nh Discord, Reddit, Linkedin, Facebook, Slack, v.v. Tham gia má»™t hoáº·c nhiá»u nhÃ³m vÃ  trao Ä‘á»•i vá»›i cÃ¡c nhÃ  nghiÃªn cá»©u giá»‘ng báº¡n sáº½ giÃºp báº¡n má»Ÿ ra nhiá»u Ä‘iá»u!
Báº¡n Ä‘Ã£ biáº¿t cÃ¡ch mÃ  mÃ¬nh tiáº¿p cáº­n cÃ¡c paper, giá» hÃ£y Ä‘i sang cÃ¡c cÃ´ng cá»¥ khuyÃªn dÃ¹ng nhÃ©!
ğŸ“Œ CÃ¡c cÃ´ng cá»¥ mÃ  báº¥t ká»³ nhÃ  khoa há»c dá»¯ liá»‡u/nhÃ  nghiÃªn cá»©u AI nÃ o cÅ©ng nÃªn cÃ³
MÃ¬nh Ä‘Ã£ Ä‘á»n cáº­p Ä‘áº¿n cÃ¡c cÃ´ng cá»¥ tÃ¬m kiáº¿m mÃ  mÃ¬nh sá»­ dá»¥ng nhÆ°: Arxiv Sanity Preserver, 42 Papers, vÃ  Papers With Code, nhÆ°ng nhá»¯ng cÃ´ng cá»¥ nÃ y khÃ´ng há»¯u Ã­ch trong viá»‡c hiá»ƒu má»™t bÃ i bÃ¡o. DÃ¹ viá»‡c hiá»ƒu má»™t bÃ i bÃ¡o sáº½ phá»¥ thuá»™c ráº¥t nhiá»u vÃ o viá»‡c báº¡n Ä‘Ã o sÃ¢u nghiÃªn cá»©u nÃ³, nhÆ°ng mÃ¬nh nháº­n ra cÃ³ khÃ¡ nhiá»u ngÆ°á»i giáº£i thÃ­ch cÃ¡c tÃ i liá»‡u nÃ y trÃªn cÃ¡c video YouTube. Tháº­t váº­y, báº¡n cÃ³ thá»ƒ tham kháº£o cÃ¡c channel cá»§a Yannic Kilcher, Whatâ€™s AI, Letitia, nhá»¯ng kÃªnh nÃ y Ä‘i sÃ¢u vÃ o cÃ¡c tÃ i liá»‡u nghiÃªn cá»©u má»›i vÃ  giáº£i thÃ­ch chÃºng má»™t cÃ¡ch rÃµ rÃ ng. Táº¥t nhiÃªn, Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quan nhanh chÃ³ng mÃ  khÃ´ng cáº§n Ä‘i sÃ¢u vÃ o lÃ½ thuyáº¿t, khÃ´ng thá»ƒ khÃ´ng nháº¯c Ä‘áº¿n Two Minute Papers. Äiá»u nÃ y sáº½ giÃºp báº¡n tiáº¿t kiá»‡m ráº¥t nhiá»u thá»i gian, Ä‘Ã³ lÃ  lÃ½ do táº¡i sao mÃ¬nh thÆ°á»ng báº¯t Ä‘áº§u báº±ng cÃ¡ch xem video cá»§a bÃ i bÃ¡o trÆ°á»›c khi Ä‘á»c nÃ³. Äiá»u tuyá»‡t vá»i hÆ¡n ná»¯a lÃ  nhá» vÃ o viá»‡c cÃ¡c paper Ä‘Æ°á»£c Ä‘Äƒng trÃªn YouTube, báº¡n sáº½ khÃ´ng cáº§n pháº£i google nÃ³ ná»¯a. Sá»­ dá»¥ng add-on cá»§a Google Chrome cÃ³ tÃªn lÃ  crossminds.ai, video sáº½ xuáº¥t hiá»‡n trá»±c tiáº¿p trÃªn trang Arxiv cá»§a bÃ i bÃ¡o báº¡n muá»‘n Ä‘á»c. Tháº­t tuyá»‡t Ä‘Ãºng khÃ´ng?! Báº¡n nÃªn thá»­ Ä‘i, mÃ¬nh cháº¯c cháº¯n Ä‘Ã¢y lÃ  Ä‘iá»u tuyá»‡t vá»i nháº¥t nÄƒm 2020 mÃ  mÃ¬nh khÃ¡m phÃ¡ ra.
TÆ°Æ¡ng tá»±, sá»­ dá»¥ng Medium cÅ©ng lÃ  má»™t cÃ¡ch Ä‘á»ƒ tÃ¬m cÃ¡c bÃ i tÃ³m táº¯t paper vÃ  cÃ¡c giáº£i thÃ­ch vá» paper Ä‘Ã³ dÃ¹ lÃ  paper trÃªn Towards AI hay Towards Data Science publications. 
Má»™t cÃ´ng cá»¥ tuyá»‡t vá»i khÃ¡c liÃªn quan Ä‘áº¿n viá»‡c á»©ng dá»¥ng paper vÃ o cÃ¡c tÃ¡c vá»¥ thá»±c táº¿. Náº¿u báº¡n tÃ¬m tháº¥y paper trÃªn Papers With Code thÃ¬ tá»‘t, code Ä‘Ã£ sáºµn sÃ ng cho báº¡n. CÃ²n náº¿u khÃ´ng, báº¡n cÃ³ thá»ƒ cáº§n google má»™t chÃºt Ä‘á»ƒ tÃ¬m cÃ¡ch triá»ƒn khai. Má»™t láº§n ná»¯a, tiá»‡n Ã­ch bá»• sung tuyá»‡t vá»i nÃ y sáº½ giÃºp báº¡n giáº£m kha khÃ¡ thá»i gian google vÃ  cung cáº¥p cho báº¡n code cá»§a báº¥t ká»³ bÃ i nghiÃªn cá»©u nÃ o trÃªn Arxiv, náº¿u cÃ³. Tiá»‡n Ã­ch nÃ y Ä‘Æ°á»£c gá»i lÃ  CatalyzeX, nÃ³ cÃ³ sáºµn trÃªn cáº£ Google Chrome vÃ  Firefox. NÃ³ cung cáº¥p cho báº¡n liÃªn káº¿t Ä‘áº¿n code trá»±c tiáº¿p trÃªn trang Arxiv, giá»‘ng nhÆ° crossmind, vÃ´ cÃ¹ng thiáº¿t thá»±c nhá»‰.
ÄÃ¢y lÃ  táº¥t cáº£ cÃ¡c máº¹o vÃ  cÃ´ng cá»¥ tá»‘t nháº¥t cá»§a mÃ¬nh Ä‘á»ƒ tÃ¬m cÃ¡c bÃ i bÃ¡o nghiÃªn cá»©u thÃ­ch há»£p vÃ  cÃ¡ch Ä‘á»c chÃºng hiá»‡u quáº£ trong khi váº«n giá»¯ láº¡i nhiá»u thÃ´ng tin nháº¥t cÃ³ thá»ƒ. Äá»‘i vá»›i mÃ¬nh, láº·p Ä‘i láº·p láº¡i viá»‡c Ä‘á»c paper cháº¯c cháº¯n lÃ  cÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ hiá»ƒu sÃ¢u, Ä‘Ã³ lÃ  lÃ½ do táº¡i sao mÃ¬nh khuyÃªn cÃ¡c báº¡n nÃªn Ä‘á»c cÃ¡c bÃ i bÃ¡o nhiá»u hÆ¡n má»™t láº§n náº¿u báº¡n thá»±c sá»± muá»‘n hiá»ƒu chÃºng. 
Sau khi báº¡n tÃ¬m tháº¥y má»™t bÃ i bÃ¡o Ä‘Ã¡ng Ä‘á»c, báº¡n nÃªn lÆ°u nÃ³ trong pháº§n má»m quáº£n lÃ½ tÃ i liá»‡u tham kháº£o nhÆ° Zotero. Pháº§n má»m nÃ y hoÃ n toÃ n miá»…n phÃ­ vÃ  cho phÃ©p báº¡n sáº¯p xáº¿p cÃ¡c paper cá»§a mÃ¬nh, dá»… dÃ ng xuáº¥t tÃ i liá»‡u tham kháº£o, lÆ°u tá»‡p PDF vÃ  hÆ¡n tháº¿ ná»¯a, táº¥t cáº£ tÃ¡c vá»¥ Ä‘Ã³ chá»‰ vá»›i má»™t cÃº nháº¥p chuá»™t Ä‘Æ¡n giáº£n. ÄÃ¢y lÃ  má»™t cÃ´ng cá»¥ tiá»‡n dá»¥ng Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai trong Word vÃ  Google Documents Ä‘á»ƒ tá»± Ä‘á»™ng táº¡o danh má»¥c cá»§a báº¡n.
ğŸ“Œ TÃ³m táº¯t cÃ¡c cÃ´ng cá»¥:
- 42 Papers â€” TÃ¬m cÃ¡c trending papers (Link: https://42papers.com/)
- Arxiv Sanity Preserver â€” ThÆ° biá»‡n cÃ¡c Arxiv papers (Link: http://www.arxiv-sanity.com/)
- Papers With Code â€”  TÃ¬m cÃ¡c paper cÃ³ kÃ¨m code Ä‘á»ƒ Ã¡p dá»¥ng vÃ o cÃ¡c task cá»¥ thá»ƒ (Link: https://paperswithcode.com/)
- Daily Papers â€” TÃ¬m kiáº¿m cÃ¡c paper trending trÃªn Twitter (Link: https://papers.labml.ai/papers/daily)
- Crossminds.ai â€”  Video giáº£i thÃ­ch cho cÃ¡c paperr Arxiv (Link: https://crossminds.ai/.../swin-transformer-hierarchical.../)
- CatalyzeX â€” Code cho háº§u háº¿t cÃ¡c Arxiv papers (Link: https://www.catalyzex.com/)
- Connected Papers â€” Táº¡o má»™t graph trá»±c quan vá» sá»± liÃªn quan cá»§a cÃ¡c nguá»“n tham kháº£o Ä‘Æ°á»£c Ä‘á» cáº­p trong paper (Link: https://www.connectedpapers.com/)
- Zotero â€“ Pháº§n má»m quáº£n lÃ½ tÃ i liá»‡u tham kháº£o (Link: https://www.zotero.org/)
- Yannic Kilcher â€” KÃªnh YouTube giáº£i thÃ­ch paper (Link: https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew)
- Whatâ€™s AI â€” KÃªnh YouTube giáº£i thÃ­ch paper (Link: https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg)
- Letitia â€” KÃªnh YouTube giáº£i thÃ­ch paper(Link: https://www.youtube.com/channel/UCobqgqE4i5Kf7wrxRxhToQA)
* Two Minute Papers â€” KÃªnh YouTube giáº£i thÃ­ch paper (Link: https://www.youtube.com/user/keeroyz)


# 

# How to Read More ResearchÂ Papers?

Do you read research papers? It can look overwhelming at first, but here's how to make it more friendly and efficient.

-   [![Louis Bouchard](https://www.louisbouchard.ai/content/images/size/w100/2021/04/profile.png)](https://www.louisbouchard.ai/author/louis/)

#### [Louis Bouchard](https://www.louisbouchard.ai/author/louis/)

Jun 23, 2021 â€¢ 9 min read

![How to Read More ResearchÂ Papers?](https://www.louisbouchard.ai/content/images/size/w2000/2021/06/0_dngn11cxwB987vDS.jpg)

Two years ago, I saw my first research paper ever. I remember how old it looked and how discouraging the mathematics inside was. It really did look like what the researchers worked on in movies. To be fair, the paper was from the 1950s, but it hasnâ€™t changed much since then. Fastforward to this day, Iâ€™ve gained a lot of experience reading them after reading a few hundred papers in the last year for my youtube channel, where I try to explain them simply. Still, I know how overwhelming a first read can be, especially the first read of your first research paper. This is why I felt like sharing **my best tips and practical tools** **I use daily** to **simplify my life and be more efficient** when looking for interesting research papers and reading them.

#### How to Find the Appropriate Papers for You?

Before reading a research paper, you must find one. So I will share some of the tools I use when looking for an interesting paper for my use case or for a video I am working on.  
_If you want to hear about the reading tips, go right to the next section!_

First of all, you need a topic. Letâ€™s say you want to study how transformers work applied to computer vision. Then, having this topic in mind, I would use [42 Papers](https://42papers.com/search?q=vision%20transformer) or [Arxiv Sanity](http://www.arxiv-sanity.com/search?q=vision+transformer) and [type in â€œvision transformersâ€](http://www.arxiv-sanity.com/search?q=vision+transformer) to collect a few papers. Both these websites are amazing collections of curated Arxiv papers facilitating your life. Suppose you have a specific task in mind, like â€œimage matting,â€ which refers to removing the background of a picture and leaving only the object of interest as the foreground. In that case, you can directly use [Papers With Code](https://paperswithcode.com/task/image-matting) as I did [here](https://paperswithcode.com/task/image-matting), which can be extremely useful, providing the current best papers for the task you want to solve with their code implementations. Again, I would select a few of the best papers for the task.

If you donâ€™t have a topic in mind, you can easily pick an interesting paper following the trends in either these fantastic tools: [42 Papers](https://42papers.com/search?q=vision%20transformer) that I just discussed or [Daily Papers](https://papers.labml.ai/papers/daily) that show all the trending papers on Twitter. It is pretty cool!

#### I Have a Few Research Papers to Read, Now What?

![](https://www.louisbouchard.ai/content/images/2021/06/cpyoshua.PNG)

![](https://www.louisbouchard.ai/content/images/2021/06/tfs1.PNG)

![](https://www.louisbouchard.ai/content/images/2021/06/neuroai.PNG)

Some fascinating research papers I recently read, and I strongly recommend reading them.

Now that you have a few research papers on your reading list, please donâ€™t read all of them one by one. Instead, I invite you to try my approach that could save you a lot of time.

First, I would check the references and confirm that the paper is worth reading or not. If there are just a few and impertinent citations, it is not a good sign. In the same way, a quick tip for helping to figure out if an article is worth reading or not is to visualize the citations. To do this, you can use a fantastic tool called [Connected Papers](https://www.connectedpapers.com/) that graphs the connections between all sources of your paper, only giving it the paper's name. This is pretty cool! If they are inter-connected and well known, there is credibility. Of course, this is just a quick indication of whether or not a paper may be interesting and well made, as it indicates that it took the time to research current approaches and investigate them. But you should not judge a paper only by its number of citations since ["nonreplicable publications are cited more than replicable ones,"](https://advances.sciencemag.org/content/7/21/eabd1705) and replicability is a clear measure of quality.

![](https://www.louisbouchard.ai/content/images/2021/06/cp.png)

Connected Paper Graph of the CVPR2021 **Best Student Paper Honorable Mentions** "[Real-Time High-Resolution Background Matting](https://arxiv.org/abs/2012.07810)"

Once it passed the first test and has trusted citations, you make the first pass for all your papers: read the title, abstract, keywords, and conclusion. See if they are really about what you are looking for. It will give you a basic idea about the paper and will help you decide whether you want to keep on reading it or not.

Second, do another pass! This time, go a bit more in-depth. Look at the graphs and tables, read their captions. You can also quickly go through the introduction and related works to see if you find it interesting and well done, but donâ€™t dive into the method and experiments right away. This takes time to digest and understand. You need to be sure it is the right paper for you. This second pass will help you get the crisp of the paper, and by then, you will already be able to summarize it and the results.

![](https://www.louisbouchard.ai/content/images/2021/06/1_xRKzf1SheH5bJmS9UdFcyQ.png)

Now that you know this is the paper for you, the list must be narrowed down. The only thing left is to read the papers that made it to this third pass! This third pass is quite obvious: you read the paper. But do not just _read_ it. **Dive in it**. Take your pencil, highlighter, or annotation tool and start reading it in silence. For this, I personally prefer to print them directly and annotate on the actual paper itself, but I am transitioning to staying on my computer screen using the PDF reader tool Adobe Acrobat Reader where you can both highlight, draw, and comment on the PDF. I used this tool by default, and I like it, but please let me know if you know a better tool for this use case! I will check it out, try it, and edit my article to add better tools.

[![](https://www.louisbouchard.ai/content/images/2021/09/imageedit_1_3899763195.png)](https://www.louisbouchard.ai/learnai/)

You should also surely Google the words and concepts you donâ€™t understand and check the citations when the authors refer to someone elseâ€™s implementation. Skipping these will hurt your understanding of the overall paper during this final read, which you may have to repeat to completely sink in the information, especially if you are a â€œbeginner paper-reader,â€ note your questions and highlight anything that seems a bit complicated or unclear. You can google the questions right away, but do not stay stuck if they remain after a second read! **Ask a friend**, or if you donâ€™t have any friends in the field to help you, **ask in a community** or forum! There are dozen of amazing communities where you can ask questions 24/7 and get an answer, that it be on Discord, Reddit, Linkedin, Facebook, Slack, etc. Join one or more and exchange with fellow researchers!

Now that you know how I personally find and read research papers after months of improving this process, you may want to keep on reading for a few more minutes as I will share the **tools that changed my life as an AI researcher**â€¦

#### The Best Tools Any Data Scientists / AI Researcher Should Have

I already talked about the amazing search tools I use: Arxiv Sanity Preserver, 42 Papers, and Papers With Code, but these arenâ€™t useful for understanding a paper. I discovered, mainly because I am myself doing it, that many people explain these research papers in YouTube videos. Indeed, some fantastic people like [Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew), [Whatâ€™s AI](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg), [Letitia](https://www.youtube.com/channel/UCobqgqE4i5Kf7wrxRxhToQA) dive into the new research papers and explain them clearly. Of course, to get a rapid overview without diving into the theory, the classic [Two Minute Papers](https://www.youtube.com/user/keeroyz) does a fantastic job. This can be of immense help and save you a lot of time and questions, which is why I often start by watching a video of the paper before reading it. What is even better is that not only do people like Yannic and I cover research papers on YouTube, but you do not have to google it anymore. Using a Google Chrome Add-On I recently discovered called [](https://medium.com/r/?url=https%3A%2F%2Fcrossminds.ai%2Fvideo%2Fswin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80%2F)[crossmind](https://crossminds.ai/video/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80/)s.ai, the videos will appear directly on the Arxiv page of the paper you want to read. How cool is that?! Here is an example where the crossmind video appears directly on the page with a recent paper called the â€œSwin Transformer,â€ which is about a transformer architecture applied to vision applications.

![](https://cdn-images-1.medium.com/max/800/1*jhEEjL3u_L2QJjfnkAGxpw.gif)

[crossmind](https://crossminds.ai/video/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80/) use-case example on the [Swin Transformer paper by Microsoft Research](https://arxiv.org/abs/2103.14030)

I must say, crossmind made me discover great YouTube channels and helped me a lot to understand research papers while saving precious time. This is, for sure, my best discovery of 2020.

Similarly, using [Medium](https://whats-ai.medium.com/membership) is a great way to find paper summaries and great explanations, either on [Towards AI](https://pub.towardsai.net/) or [](https://pub.towardsai.net/)[Towards Data Science publications](https://towardsdatascience.com/). I also share my own articles there and I love the platform. You can subscribe to medium using my affiliated link [here](https://whats-ai.medium.com/membership) if you'd like to support me at the same time!

Another pretty amazing tool is more related to implementing these papers. Obviously, if you reached the third pass of my guide, it probably means that the paper is worth reading to you, but I would also bet my right arm that you would like to implement it and make it work. If you found your paper on Papers With Code, then you are already good to go. Otherwise, you may need some Googling to find the official implementation or just an unofficial implementation to start with. Again, this [awesome add-on](https://www.catalyzex.com/) removes the Googling need and gives you the code of any research paper on Arxiv, _if applicable_. This precious add-on is called CatalyzeX, and it is available on both Google Chrome and Firefox. It gives you the link to the code directly on the Arxiv page, just like crossmind, which is incredibly practical.

![](https://cdn-images-1.medium.com/max/800/1*7yOHk36DfVi79hCUDbAVbw.gif)

[CatalyzeX](https://www.catalyzex.com/) use-case example on the [Swin Transformer paper by Microsoft Research](https://arxiv.org/abs/2103.14030)

Here were all my best tips and tools for finding the most appropriate research papers for you, reading them as efficiently as possible while retaining the most information possible. To me, **repetition is surely the best way to learn**, which is why I recommended reading the papers more than once if you really want to understand them. **Repetition from different learning sources** is also an incredible advantage when it comes to learning something new. In our case, we can easily profit from this with YouTube. Indeed, you can simply listen to someone explain the paper to you for free, giving your brain other sensorial queues to sink in even more information. This is an incredible advantage this field has, and you must exploit it!

Once you found an interesting paper, I strongly recommend you save it in a reference management software like [Zotero](https://www.zotero.org/). It is entirely free and allows you to organize your papers, easily export references, save PDFs, and more with a simple click. It is a handy tool already implemented in Word and Google Docs to generate your bibliographies automatically.

#### A Few Words on Bias and Trustworthiness

There are no tips to detecting how trustworthy a paper is other than carefully reading and analyze the experiment section and see if it fits the methodology. You should never take what the authors wrote for free as, even if they were sincere, something might have changed since then, or they may have made a mistake during the experiments or when concluding based on their results. Similarly, you should not blindly trust the experiment section. You should also double-check the plots and tables to see if the scalings are the same, to be sure the authors didnâ€™t try to eye trick the reader to make us misleadingly feel like they are better by a clear margin. As you know, the conclusion is simply what the authors concluded from their results. This means that even if itâ€™s a great and quick way to understand what the paper is about, the conclusion is also subject to errors and author bias. It also means that you couldâ€™ve come to a different conclusion from the same experiments and results.

#### Conclusion

In final words, the only way to get better at reading papers and more efficient is to read papers. Donâ€™t be afraid and dive in! The more you read, the better you will become. Start with videos about research papers and then dive into them with a fresh explanation in mind. It will be much easier.

Thank you for reading! Let me know if you have any more tips I may have missed that I could benefit from, always keen to learn!

â€”â€ŠLouis

Come chat with us in our [****Discord community:**** ****Learn AI Together****](https://discord.gg/learnaitogether) and __share your projects, papers, best courses, find Kaggle teammates, and much more!__

If you like my work and want to stay up-to-date with AI, you should definitely follow me on my other social media accounts ([LinkedIn](https://www.linkedin.com/in/whats-ai/), [Twitter](https://twitter.com/Whats_AI)) and subscribe to my weekly AI [****newsletter****](http://eepurl.com/huGLT5)!

### To support me:

-   The best way to support me is by being a member of this website or subscribe to my channel on [****YouTube****](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg) if you like the video format.
-   Support my work financially on [****Patreon****](https://www.patreon.com/whatsai)

### References

-   [42 Papers](https://42papers.com/)â€Šâ€”â€ŠFind trending papers
-   [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/)â€Šâ€”â€ŠA Curation list of Arxiv papers
-   [Papers With Code](https://paperswithcode.com/)â€Šâ€”â€ŠFind papers for your task with code!
-   [Daily Papers](https://papers.labml.ai/papers/daily)â€Šâ€”â€ŠFind trending papers on Twitter
-   [](https://medium.com/r/?url=https%3A%2F%2Fcrossminds.ai%2Fvideo%2Fswin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80%2F)[Crossmind](https://crossminds.ai/video/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80/)s.aiâ€Šâ€”â€ŠVideo explanations for many Arxiv papers
-   [CatalyzeX](https://www.catalyzex.com/)â€Šâ€”â€ŠCode implementation for most Arxiv papers
-   [Connected Papers](https://www.connectedpapers.com/)â€Šâ€”â€ŠCreate a visual graph with your paperâ€™s citationsâ€™ relations.
-   [Zotero](https://www.zotero.org/) â€“ Reference management software
-   [Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew)â€Šâ€”â€ŠGreat youtube channel covering AI papers
-   [Whatâ€™s AI](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg)â€Šâ€”â€ŠGreat youtube channel covering AI papers
-   [Letitia](https://www.youtube.com/channel/UCobqgqE4i5Kf7wrxRxhToQA)â€Šâ€”â€ŠGreat youtube channel covering AI papers
-   [Two Minute Papers](https://www.youtube.com/user/keeroyz)â€Šâ€”â€ŠGreat youtube channel giving a quick overview of AI papers


# 

---
Status: #writing

Tags: 

References:
- [source](https://www.louisbouchard.ai/research-papers/)

Related:
- 
